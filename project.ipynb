{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f521d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_master_list = [\n",
    "    \"Bilbo\", \"Bungo\", \"Belladonna\", \"Gandalf\", \"Radagast\", \"Thorin\", \"Balin\", \"Dwalin\", \"Kili\", \"Fili\", \"Dori\", \"Nori\", \"Ori\", \"Oin\", \"Gloin\", \"Bifur\", \"Bofur\", \"Bombur\", \"Elrond\", \"Thranduil\", \"Bard\", \"Beorn\", \"Smaug\", \"Gollum\", \"Bolg\", \"RoÃ¤c\", \"Tom\", \"Bert\", \"William\",\n",
    "    \"Frodo\", \"Samwise\", \"Sam\", \"Meriadoc\", \"Merry\", \"Peregrin\", \"Pippin\", \"Rosie\", \"Fatty\", \"Saruman\", \"Aragorn\", \"Boromir\", \"Faramir\", \"Denethor\", \"Theoden\", \"Eomer\", \"Eowyn\", \"Grima\", \"Wormtongue\" \"Hama\", \"Hirgon\", \"Imrahil\", \"Beregond\", \"Bergil\", \"Halbarad\", \"Elladan\", \"Elrohir\", \"Legolas\", \"Galadriel\", \"Celeborn\", \"Arwen\", \"Glorfindel\", \"Haldir\", \"Dain\", \"Smjagol\", \"Treebeard\", \"Quickbeam\", \"Huorns\", \"Shelob\", \"Sauron\", \"Nazgul\", \"Grishnakh\", \"Ugluk\", \"Shagrat\", \"Gorbag\", \"Shadowfax\", \"Bill\", \"Snowmane\", \"Hasufel\", \"Arod\", \"Tom\", \"Goldberry\", \"Barliman\", \"Butterbur\",\n",
    "\n",
    "    \"Lucy\", \"Edmund\", \"Susan\", \"Peter\", \"Aslan\", \"Tumnus\", \"Beaver\", \"Maugrim\", \"Kirke\", \"Macready\", \"Oreius\", \"Otmin\",\n",
    "    \"Caspian\", \"Cornelius\", \"Trufflehunter\", \"Trumpkin\", \"Reepicheep\", \"Nikabrik\", \"Glenstorm\", \"Pattertwig\", \"Miraz\", \"Prunaprismia\", \"Glozelle\", \"Sopespian\",\n",
    "\n",
    "    \"Mary\", \"Poppins\", \"George\", \"Winifred\", \"Jane\", \"Michael\", \"John\", \"Barbara\", \"Banks\", \"Brill\", \"Ellen\", \"Robertson\", \"Bert\", \"Boom\", \"Lark\", \"Andrew\", \"Corry\", \"Neleus\", \"Albert\", \"Arthur\",\n",
    "\n",
    "    \"Robert\", \"Virginia\", \"Kathy\", \"Neville\", \"Ruth\", \"Ben\", \"Josephine\", \"Soames\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb055e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from functools import reduce\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8b3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Create Tolkien Data Frame\n",
    "\n",
    "file_list = glob.glob(os.path.join(\"Tolkien\", \"*\", \"*.txt\"))\n",
    "basename = \"Tolkien\"\n",
    "data = []\n",
    "for f in file_list:\n",
    "    book = os.path.basename(os.path.dirname(f))   # folder name = book title\n",
    "    chapter = os.path.basename(f).replace(\".txt\", \"\")\n",
    "    text = open(f, \"r\", encoding=\"utf-8\").read()\n",
    "    data.append({\"book\": book, \"chapter\": chapter, \"raw_text\": text})\n",
    "\n",
    "Tolkien_df = pd.DataFrame(data)\n",
    "\n",
    "# Create C.S. Lewis Data Frame\n",
    "\n",
    "file_list = glob.glob(os.path.join(\"CS_Lewis\", \"*\", \"*.txt\"))\n",
    "basename = \"CS_Lewis\"\n",
    "data = []\n",
    "for f in file_list:\n",
    "    book = os.path.basename(os.path.dirname(f))   # folder name = book title\n",
    "    chapter = os.path.basename(f).replace(\".txt\", \"\")\n",
    "    text = open(f, \"r\", encoding=\"utf-8\").read()\n",
    "    data.append({\"book\": book, \"chapter\": chapter, \"raw_text\": text})\n",
    "\n",
    "Lewis_df = pd.DataFrame(data)\n",
    "\n",
    "# Create P.L. Travers Data Frame\n",
    "\n",
    "file_list = glob.glob(os.path.join(\"PL_Travers\", \"*\", \"*.txt\"))\n",
    "basename = \"PL_Travers\"\n",
    "data = []\n",
    "for f in file_list:\n",
    "    book = os.path.basename(os.path.dirname(f))   # folder name = book title\n",
    "    chapter = os.path.basename(f).replace(\".txt\", \"\")\n",
    "    text = open(f, \"r\", encoding=\"utf-8\").read()\n",
    "    data.append({\"book\": book, \"chapter\": chapter, \"raw_text\": text})\n",
    "\n",
    "Travers_df = pd.DataFrame(data)\n",
    "\n",
    "# Create Matheson Data Frame\n",
    "\n",
    "file_list = glob.glob(os.path.join(\"Matheson\", \"*\", \"*.txt\"))\n",
    "basename = \"Matheson\"\n",
    "data = []\n",
    "for f in file_list:\n",
    "    book = os.path.basename(os.path.dirname(f))   # folder name = book title\n",
    "    chapter = os.path.basename(f).replace(\".txt\", \"\")\n",
    "    text = open(f, \"r\", encoding=\"utf-8\").read()\n",
    "    data.append({\"book\": book, \"chapter\": chapter, \"raw_text\": text})\n",
    "\n",
    "Matheson_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ecb0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r'chapter\\s+\\w+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r\"'s$\", \"\", text)\n",
    "    pattern = r\"\\b(\" + \"|\".join(re.escape(name) for name in names_master_list) + r\")\\b\"\n",
    "    text = re.sub(pattern, \"X\", text, flags=re.IGNORECASE)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9679eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tolkien_df[\"clean_text\"] = Tolkien_df[\"raw_text\"].apply(clean_text)\n",
    "Lewis_df[\"clean_text\"] = Lewis_df[\"raw_text\"].apply(clean_text)\n",
    "Travers_df[\"clean_text\"] = Travers_df[\"raw_text\"].apply(clean_text)\n",
    "Matheson_df[\"clean_text\"] = Matheson_df[\"raw_text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbf9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops_and_punct(text):\n",
    "    # Tokenize and lowercase\n",
    "    tokens = [t.lower() for t in word_tokenize(text)]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [t for t in tokens if t not in string.punctuation]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    english_stops = stopwords.words(\"english\")\n",
    "    tokens = [t for t in tokens if t not in english_stops]\n",
    "\n",
    "    # Join into a string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb48ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "Tolkien_df[\"words\"] = Tolkien_df[\"clean_text\"].apply(remove_stops_and_punct)\n",
    "Lewis_df[\"words\"] = Lewis_df[\"clean_text\"].apply(remove_stops_and_punct)\n",
    "Travers_df[\"words\"] = Travers_df[\"clean_text\"].apply(remove_stops_and_punct)\n",
    "Matheson_df[\"words\"] = Matheson_df[\"clean_text\"].apply(remove_stops_and_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fad8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_stops(text):\n",
    "    # Tokenize and lowercase\n",
    "    tokens = [t.lower() for t in word_tokenize(text)]\n",
    "    \n",
    "    # Keep only stopwords\n",
    "    english_stops = stopwords.words(\"english\")\n",
    "    tokens = [t for t in tokens if t in english_stops]\n",
    "\n",
    "    # Join into a string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8fca465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only stopwords\n",
    "Tolkien_df[\"stops\"] = Tolkien_df[\"clean_text\"].apply(only_stops)\n",
    "Lewis_df[\"stops\"] = Lewis_df[\"clean_text\"].apply(only_stops)\n",
    "Travers_df[\"stops\"] = Travers_df[\"clean_text\"].apply(only_stops)\n",
    "Matheson_df[\"stops\"] = Matheson_df[\"clean_text\"].apply(only_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f37818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct(text):\n",
    "    # Tokenize and lowercase\n",
    "    tokens = [t.lower() for t in word_tokenize(text)]\n",
    "    \n",
    "    # Keep only punctuation\n",
    "    tokens = [t for t in tokens if t in string.punctuation]\n",
    "    \n",
    "    # Join into a string\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4ce7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only punctuation\n",
    "Tolkien_df[\"punct\"] = Tolkien_df[\"clean_text\"].apply(punct)\n",
    "Lewis_df[\"punct\"] = Lewis_df[\"clean_text\"].apply(punct)\n",
    "Travers_df[\"punct\"] = Travers_df[\"clean_text\"].apply(punct)\n",
    "Matheson_df[\"punct\"] = Matheson_df[\"clean_text\"].apply(punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e137a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1382625415137214\n"
     ]
    }
   ],
   "source": [
    "# Unique word count\n",
    "def unique_word_ratio(text_df, text):\n",
    "    this_df = text_df[text_df[\"book\"] == text]\n",
    "    this_full_text = \" \".join(this_df[\"words\"])\n",
    "    return len(set(this_full_text.split())) / len(this_full_text.split())\n",
    "hobbit_unique_word_ratio = unique_word_ratio(Tolkien_df, \"Hobbit\")\n",
    "print(hobbit_unique_word_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3c5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.72, 214]\n"
     ]
    }
   ],
   "source": [
    "# Average sentence length\n",
    "def avg_sent_len(text_df, text):\n",
    "    this_df = text_df[text_df[\"book\"] == text]\n",
    "    tokenized_text = word_tokenize(\" \".join(this_df[\"clean_text\"]))\n",
    "    sent_lengths = []\n",
    "    length = 0\n",
    "    for token in tokenized_text:\n",
    "        if token != \".\":\n",
    "            length += 1\n",
    "        else:\n",
    "            sent_lengths.append(length)\n",
    "            length = 0\n",
    "    avg_len = 0\n",
    "    for i in sent_lengths:\n",
    "        avg_len += i\n",
    "    avg_len /= len(sent_lengths)\n",
    "    avg_len = round(avg_len, 2)\n",
    "    return [avg_len, max(sent_lengths)]\n",
    "\n",
    "hobbit_avg_len = avg_sent_len(Tolkien_df, \"Hobbit\")\n",
    "print(hobbit_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56988245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', 2781), ('x', 1710), ('said', 568), ('could', 368), (\"'s\", 328), ('one', 284), ('dwarves', 275), ('came', 244), ('would', 239), (\"n't\", 236), ('like', 221), ('long', 215), ('time', 214), ('back', 208), ('come', 197), ('great', 179), ('still', 173), ('good', 168), ('see', 161), ('go', 161), ('went', 161), ('little', 160), ('last', 160), ('far', 159), ('goblins', 153), ('way', 151), ('even', 143), ('dark', 141), ('got', 140), ('get', 136), ('soon', 135), ('well', 134), ('hobbit', 133), ('mountain', 131), ('many', 127), ('away', 126), ('made', 122), ('thought', 121), ('light', 116), ('old', 114), ('though', 112), ('never', 111), ('us', 111), ('ever', 111), ('round', 108), ('know', 108), ('must', 106), ('much', 105), ('door', 100), ('going', 100)]\n"
     ]
    }
   ],
   "source": [
    "# Most frequent words\n",
    "def most_frequent_words(text_df, text):\n",
    "    this_df = text_df[text_df[\"book\"] == text]\n",
    "    this_full_text = word_tokenize(\" \".join(this_df[\"words\"]))\n",
    "    this_words_freq = FreqDist(this_full_text).most_common(50)\n",
    "    return this_words_freq\n",
    "hobbit_mfw = most_frequent_words(Tolkien_df, \"Hobbit\")\n",
    "print(hobbit_mfw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0380745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 5755), ('and', 4260), ('of', 2341), ('to', 2015), ('a', 1878), ('he', 1850), ('in', 1399), ('was', 1328), ('they', 1324), ('it', 1186), ('that', 1020), ('had', 898), ('his', 877), ('i', 829), ('you', 820), ('on', 745), ('not', 726), ('for', 703), ('as', 665), ('were', 654), ('all', 641), ('at', 635), ('with', 623), ('but', 622), ('them', 524), ('there', 513), ('their', 508), ('is', 493), ('have', 437), ('him', 434), ('from', 393), ('be', 361), ('up', 360), ('out', 350), ('or', 344), ('we', 325), ('are', 307), ('down', 306), ('if', 306), ('no', 296), ('what', 295), ('now', 293), ('so', 284), ('by', 278), ('do', 266), ('this', 262), ('when', 262), ('then', 253), ('very', 246), ('into', 234)]\n"
     ]
    }
   ],
   "source": [
    "# Most frequent stopwords\n",
    "def most_frequent_stopwords(text_df, text):\n",
    "    this_df = text_df[text_df[\"book\"] == text]\n",
    "    this_stops = word_tokenize(\" \".join(this_df[\"stops\"]))\n",
    "    this_stops_freq = FreqDist(this_stops).most_common(50)\n",
    "    return this_stops_freq\n",
    "hobbit_mfs = most_frequent_stopwords(Tolkien_df, \"Hobbit\")\n",
    "print(hobbit_mfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea448beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 5455), ('.', 4332), ('!', 992), (';', 593), ('?', 312), (':', 164), ('(', 116), (')', 116), (\"'\", 89), ('-', 23), ('*', 6), ('&', 1), ('}', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Most frequent punctuation\n",
    "def most_frequent_punct(text_df, text):\n",
    "    this_df = text_df[text_df[\"book\"] == text]\n",
    "    this_punct = word_tokenize(\" \".join(this_df[\"punct\"]))\n",
    "    this_punct_freq = FreqDist(this_punct).most_common(25)\n",
    "    return this_punct_freq\n",
    "hobbit_mfp = most_frequent_punct(Tolkien_df, \"Hobbit\")\n",
    "print(hobbit_mfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd30fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object type to represent the data from each book\n",
    "class Book:\n",
    "  def __init__(self, author_df, book):\n",
    "    self.title = book\n",
    "    self.vocab_richness = unique_word_ratio(author_df, book)\n",
    "    self.sentence_length = avg_sent_len(author_df, book)\n",
    "    self.most_common_words = most_frequent_words(author_df, book)\n",
    "    self.most_common_stopwords = most_frequent_stopwords(author_df, book)\n",
    "    self.most_common_punct = most_frequent_punct(author_df, book)\n",
    "\n",
    "  def get_data(self):\n",
    "    return([self.vocab_richness, self.sentence_length, self.most_common_words, self.most_common_stopwords, self.most_common_punct])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e955854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Author:\n",
    "    def __init__(self, name, books):\n",
    "        self.name = name\n",
    "        self.books = books\n",
    "        self.vocab_richness = sum(book.vocab_richness for book in books) / len(books)\n",
    "        self.sentence_length = sum(book.sentence_length[0] for book in books) / len(books)\n",
    "        self.most_common_words = FreqDist(word for book in books for word, count in book.most_common_words for _ in range(count)).most_common(50)\n",
    "        self.most_common_stopwords = FreqDist(word for book in books for word, count in book.most_common_stopwords for _ in range(count)).most_common(50)\n",
    "        self.most_common_punct = FreqDist(word for book in books for word, count in book.most_common_punct for _ in range(count)).most_common(25)\n",
    "\n",
    "    def get_data(self):\n",
    "        return([self.vocab_richness, self.sentence_length, self.most_common_words, self.most_common_stopwords, self.most_common_punct])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "581e12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "The_Hobbit = Book(Tolkien_df, \"Hobbit\")\n",
    "Fellowship = Book(Tolkien_df, \"Fellowship\")\n",
    "Two_Towers = Book(Tolkien_df, \"Two_Towers\")\n",
    "Return = Book(Tolkien_df, \"Return\")\n",
    "\n",
    "Tolkien = Author(\"Tolkien\", [The_Hobbit, Fellowship, Two_Towers, Return])\n",
    "\n",
    "Lion = Book(Lewis_df, \"Lion\")\n",
    "Caspian = Book(Lewis_df, \"Caspian\")\n",
    "\n",
    "Lewis = Author(\"Lewis\", [Lion, Caspian])\n",
    "\n",
    "Poppins = Book(Travers_df, \"Poppins\")\n",
    "\n",
    "Travers = Author(\"Travers\", [Poppins])\n",
    "\n",
    "Legend = Book(Matheson_df, \"Legend\")\n",
    "\n",
    "Matheson = Author(\"Matheson\", [Legend])\n",
    "\n",
    "authors = [Tolkien, Lewis, Travers, Matheson]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd1770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_1 = Book(Tolkien_df, \"Test_1\")\n",
    "Test_2 = Book(Lewis_df, \"Test_2\")\n",
    "Test_3 = Book(Travers_df, \"Test_3\")\n",
    "Test_4 = Book(Matheson_df, \"Test_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77293a",
   "metadata": {},
   "source": [
    "**Metrices for comparison:**\n",
    "\n",
    "Vocabulary richness\n",
    "\n",
    "Average sentence length\n",
    "\n",
    "50 most common words\n",
    "\n",
    "50 most common stopwords\n",
    "\n",
    "25 most common punctuative items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c169525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_books(book1, book2):\n",
    "    book1_data = book1.get_data()\n",
    "    book2_data = book2.get_data()\n",
    "    vocab_diff = 1 - abs(book1_data[0] - book2_data[0])\n",
    "    sent_len = 1 - (abs(book1_data[1][0] - book2_data[1][0]) / max([book1_data[1][1], book2_data[1][1]]))\n",
    "    words_diff = len(set(word for word, count in book1_data[2]) & set(word for word, count in book2_data[2])) / 50\n",
    "    words_diff_set = set(word for word, count in book1_data[2]) & set(word for word, count in book2_data[2])\n",
    "    stopwords_diff = len(set(word for word, count in book1_data[3]) & set(word for word, count in book2_data[3])) / 50\n",
    "    stopwords_diff_set = set(word for word, count in book1_data[3]) & set(word for word, count in book2_data[3])\n",
    "    punct_diff = len(set(word for word, count in book1_data[4]) & set(word for word, count in book2_data[4])) / 25\n",
    "    punct_diff_set = set(word for word, count in book1_data[4]) & set(word for word, count in book2_data[4])\n",
    "    return [vocab_diff, sent_len, words_diff, words_diff_set, stopwords_diff, stopwords_diff_set, punct_diff, punct_diff_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6bfc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_value_for_comparison(values):\n",
    "    # Standard deviation of vocabulary richness\n",
    "    vocabs = []\n",
    "    for entry in values:\n",
    "        vocabs.append(entry[0])\n",
    "    if len(values) > 1:\n",
    "        vocab = 1 - statistics.stdev(vocabs)\n",
    "    else:\n",
    "        vocab = entry[0]\n",
    "    # So that a high value means that the vocabulary richnesses are similar\n",
    "\n",
    "    # Standard deviation of average sentence lengths\n",
    "    lens = []\n",
    "    for entry in values:\n",
    "        lens.append(entry[1])\n",
    "    if len(values) > 1:\n",
    "        lent = 1 - statistics.stdev(lens)\n",
    "    else:\n",
    "        lent = entry[1]\n",
    "\n",
    "    # Proportion of 50 most common words shared by all compared texts\n",
    "    words_diff = len(reduce(lambda x, y: x & y, (row[3] for row in values))) / 50\n",
    "\n",
    "    # Proportion of 50 most common stopwords shared by all compared texts\n",
    "    stopwords_diff = len(reduce(lambda x, y: x & y, (row[5] for row in values))) / 50\n",
    "\n",
    "    # Proportion of 25 most common puncts shared by all compared texts\n",
    "    puncts_diff = len(reduce(lambda x, y: x & y, (row[7] for row in values))) / 25\n",
    "\n",
    "    return (vocab + lent + words_diff + stopwords_diff + puncts_diff) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aeeb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_text(text):\n",
    "    summary_comparisons = {}\n",
    "    # Get a dictionary with author and a number from 0 to 1 predicting how similar the text is to the author's other works\n",
    "    for author in authors:\n",
    "        comparisons = []\n",
    "        for book in author.books:\n",
    "            comparisons.append(compare_books(text, book))\n",
    "        summary_comparisons[author] = get_one_value_for_comparison(comparisons)\n",
    "\n",
    "    # Go through each author and their likelihood of having written this text, get the most likely one\n",
    "    highest = 0\n",
    "    guess_author = \"\"\n",
    "    for key, value in summary_comparisons.items():\n",
    "        if value > highest:\n",
    "            highest = value\n",
    "            guess_author = key.name\n",
    "    \n",
    "    print(\"The author of this text is most likely\", guess_author, \"with similarity\", round(highest * 100, 2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c7822a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of this text is most likely Tolkien with similarity 75.16 %\n",
      "The author of this text is most likely Lewis with similarity 70.25 %\n",
      "The author of this text is most likely Travers with similarity 66.46 %\n",
      "The author of this text is most likely Matheson with similarity 69.81 %\n"
     ]
    }
   ],
   "source": [
    "test_new_text(Test_1) # Sample of chapter 10 from each of the four Tolkien books\n",
    "test_new_text(Test_2) # Sample of chapters 14 and 15 from C.S. Lewis' The Lion, The Witch, and the Wardrobe\n",
    "test_new_text(Test_3) # Sample of chapter 12 from P.L. Travers' Mary Poppins\n",
    "test_new_text(Test_4) # Sample of chapters 20 and 21 from Matheson's I Am Legend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
